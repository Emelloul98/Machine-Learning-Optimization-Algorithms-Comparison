# Machine Learning Optimization Algorithms Comparison

An analysis comparing various machine learning optimization algorithms, including Stochastic Gradient Descent (SGD), Batch Gradient Descent, and their SVD-based counterparts for dimensionality reduction. The project includes performance testing and visualizations to evaluate algorithm convergence and efficiency.

---

**Features:**
1. Comparison of SGD, Batch SGD, and their SVD versions.
2. Performance testing and execution time comparison.
3. Visualizations for algorithm convergence.
4. Data preprocessing using Singular Value Decomposition (SVD).

---

**Components:**
1. Python scripts for algorithm implementation.
2. Jupyter Notebooks for data analysis and visualization.
3. CSV data files for testing and evaluation.

---

**Running the Comparisons:**
1. Ensure Python and necessary libraries (NumPy, pandas, matplotlib) are installed.
2. Open the Jupyter Notebook files to run and visualize the comparisons.
3. Modify parameters and datasets for specific experiments.
4. Analyze the results and conclusions drawn from the comparisons.

---

**Example Visualizations:**

- Convergence plots for SGD, Batch SGD, and SVD-aided optimizations.
- Execution time comparisons for different algorithm configurations.
- Dimensionality reduction impact on optimization performance.

![Image Alt Text](https://github.com/Emelloul98/Machine-Learning-Optimization-Algorithms-Comparison/blob/main/image2.png)
![Image Alt Text](https://github.com/Emelloul98/Machine-Learning-Optimization-Algorithms-Comparison/blob/main/image1.png)
